<div align="center">
  <img src="docs/logo.png" alt="kiro2chat logo" width="128" height="128">
  <h1>kiro2chat</h1>
  <p><strong>Kiro â†’ Standard API Gateway</strong></p>
  <p>Wrap Kiro CLI's Claude Opus 4.6 backend into a fully compatible OpenAI + Anthropic API Gateway</p>

  **[English](README.md)** | **[ä¸­æ–‡](README_CN.md)**

  ![Python](https://img.shields.io/badge/python-â‰¥3.13-blue?logo=python&logoColor=white)
  ![FastAPI](https://img.shields.io/badge/FastAPI-0.129+-green?logo=fastapi&logoColor=white)
  ![License](https://img.shields.io/badge/license-MIT-blue)
  ![Version](https://img.shields.io/badge/version-1.0.0-purple)
</div>

---

## âœ¨ Features

- ğŸ”„ **Dual Protocol** â€” Supports both OpenAI `/v1/chat/completions` and Anthropic `/v1/messages` formats
- ğŸ§  **Claude Opus 4.6 1M** â€” Backend always uses the most powerful model with 1M context window
- ğŸ§¹ **System Prompt Sanitization** â€” Three-layer defense to strip Kiro IDE injected prompts and tool definitions
- ğŸ› ï¸ **Full Tool Calling** â€” Tool definitions, tool_choice, tool_result round-trip, MCP tool support
- ğŸ“¡ **Stream + Non-Stream** â€” Both API formats support SSE streaming and synchronous responses
- ğŸ”‘ **Auto Token Management** â€” Reads and auto-refreshes IdC tokens from kiro-cli SQLite
- ğŸ“Š **Token Usage Estimation** â€” CJK-aware character-based token counting
- ğŸ¤– **Strands Agent** â€” Optional agent layer with MCP tool support
- ğŸŒ **Web UI** â€” Gradio multi-page interface (chat, monitoring, config)
- ğŸ“± **Telegram Bot** â€” Bot powered by the agent layer

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Client Layer                          â”‚
â”‚                                                              â”‚
â”‚  OpenAI SDK â”€â”€â”                                              â”‚
â”‚  Anthropic SDKâ”¤â”€â”€â†’ /v1/chat/completions (OpenAI format)      â”‚
â”‚  Claude Code â”€â”¤â”€â”€â†’ /v1/messages         (Anthropic format)   â”‚
â”‚  Any Client  â”€â”˜                                              â”‚
â”‚                           â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Protocol Layer                             â”‚
â”‚                           â”‚                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚    â”‚  Anti-Prompt Injection (sanitizer.py)        â”‚           â”‚
â”‚    â”‚  â†’ Strips Kiro IDE system prompt             â”‚           â”‚
â”‚    â”‚  â†’ Blocks IDE tool leakage                   â”‚           â”‚
â”‚    â”‚  â†’ Enforces Claude identity                  â”‚           â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                           â”‚                                  â”‚
â”‚    OpenAI/Anthropic â†’ CodeWhisperer (converter.py)           â”‚
â”‚    EventStream Binary â†’ JSON (eventstream.py)                â”‚
â”‚    Response â†’ Sanitized Output (sanitizer.py)                â”‚
â”‚                           â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Auth Layer                                â”‚
â”‚    kiro-cli SQLite â†’ IdC Token Auto-Refresh                  â”‚
â”‚    (~/.local/share/kiro-cli/data.sqlite3)                    â”‚
â”‚                           â”‚                                  â”‚
â”‚                           â†“                                  â”‚
â”‚    CodeWhisperer API (claude-opus-4.6-1m)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ API Endpoints

| Endpoint | Method | Format | Description |
|----------|--------|--------|-------------|
| `/v1/chat/completions` | POST | OpenAI | Chat completions (stream + non-stream) |
| `/v1/models` | GET | OpenAI | List available models |
| `/v1/messages` | POST | Anthropic | Messages API (stream + non-stream) |
| `/v1/messages/count_tokens` | POST | Anthropic | Token count estimation |
| `/v1/messages/batches` | POST | Anthropic | Batch API (stub, 501) |
| `/v1/agent/chat` | POST | Custom | Strands Agent chat |
| `/v1/agent/tools` | GET | Custom | List loaded tools |
| `/health` | GET | â€” | Health check |
| `/` | GET | â€” | Service info |

## ğŸš€ Quick Start

### Prerequisites

```bash
# 1. Install kiro-cli and login
kiro-cli login

# 2. Clone and install
git clone https://github.com/neosun100/kiro2chat.git
cd kiro2chat
uv sync
```

### Run

```bash
# API server only (port 8000)
uv run kiro2chat api

# Web UI (port 7860)
uv run kiro2chat webui

# Telegram Bot
uv run kiro2chat bot

# All together
uv run kiro2chat all
```

### Use with OpenAI SDK

```python
from openai import OpenAI

client = OpenAI(base_url="http://localhost:8000/v1", api_key="not-needed")

response = client.chat.completions.create(
    model="claude-opus-4.6-1m",  # Any model name works
    messages=[{"role": "user", "content": "Hello!"}],
)
print(response.choices[0].message.content)
```

### Use with Anthropic SDK

```python
import anthropic

client = anthropic.Anthropic(base_url="http://localhost:8000", api_key="not-needed")

message = client.messages.create(
    model="claude-opus-4.6-1m",
    max_tokens=1024,
    messages=[{"role": "user", "content": "Hello!"}],
)
print(message.content[0].text)
```

### Use with curl

```bash
# OpenAI format
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "gpt-4o", "messages": [{"role": "user", "content": "Hello"}]}'

# Anthropic format
curl http://localhost:8000/v1/messages \
  -H "Content-Type: application/json" \
  -d '{"model": "claude-opus-4.6-1m", "max_tokens": 1024, "messages": [{"role": "user", "content": "Hello"}]}'
```

## ğŸ”§ API Compatibility

### OpenAI `/v1/chat/completions`

| Feature | Status |
|---------|--------|
| Text generation (stream + non-stream) | âœ… |
| System / Developer role messages | âœ… |
| Multi-turn conversations | âœ… |
| Tool definitions + tool_calls | âœ… |
| Tool result round-trip | âœ… |
| tool_choice (none/auto/required) | âœ… |
| temperature / top_p / stop | âœ… |
| presence_penalty / frequency_penalty | âœ… |
| stream_options (include_usage) | âœ… |
| Any model name accepted | âœ… |
| Incremental streaming tool_calls | âœ… |
| MCP tool calling | âœ… |
| Token usage estimation | âœ… |

### Anthropic `/v1/messages`

| Feature | Status |
|---------|--------|
| Text generation (stream + non-stream) | âœ… |
| System prompt (string + content blocks) | âœ… |
| Multi-turn conversations | âœ… |
| Tool definitions (Anthropic format) | âœ… |
| tool_result round-trip | âœ… |
| tool_choice (auto/any/tool/none) | âœ… |
| Image blocks (base64 + URL) | âœ… |
| Thinking blocks (passthrough) | âœ… |
| stop_sequences | âœ… |
| SSE events (message_start/delta/stop) | âœ… |
| input_json_delta streaming | âœ… |
| count_tokens endpoint | âœ… |
| Token usage estimation | âœ… |

## ğŸ§¹ System Prompt Sanitization

Kiro's CodeWhisperer backend injects an IDE system prompt containing tool definitions (readFile, fsWrite, webSearch, etc.) that don't exist outside the IDE. kiro2chat implements **three-layer defense**:

1. **Anti-Prompt Injection** â€” Prepends a high-priority override declaring the true identity (Claude by Anthropic) and explicitly denying all IDE tools while encouraging user-provided tools
2. **Assistant Confirmation** â€” Injects a fake assistant turn confirming it will ignore IDE tools but actively use user-provided tools
3. **Response Sanitization** â€” Regex-based post-processing strips leaked tool names, Kiro identity references, and XML markup

**Result**: 28/28 adversarial test scenarios pass with zero leakage.

## âš™ï¸ Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `HOST` | `0.0.0.0` | Server bind address |
| `PORT` | `8000` | API server port |
| `KIRO_DB_PATH` | `~/.local/share/kiro-cli/data.sqlite3` | kiro-cli database path |
| `API_KEY` | *(none)* | Optional API authentication key |
| `TG_BOT_TOKEN` | *(none)* | Telegram Bot token |
| `LOG_LEVEL` | `info` | Logging level |

### Model Mapping

All model names are accepted. The backend always uses `claude-opus-4.6-1m`. Common aliases:

| Client sends | Backend uses |
|---|---|
| `gpt-4o`, `gpt-4`, `gpt-3.5-turbo` | `claude-opus-4.6-1m` |
| `claude-opus-4.6-1m`, `claude-opus-4.6` | `claude-opus-4.6-1m` |
| `claude-sonnet-4.5`, `claude-sonnet-4` | `claude-opus-4.6-1m` |
| Any other string | `claude-opus-4.6-1m` |

## ğŸš¢ Deployment

### Systemd Service

```bash
sudo cp kiro2chat@.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable --now kiro2chat@$(whoami)
```

### Environment Variables

```bash
nohup env API_KEY="your-key" PORT="8800" HOST="0.0.0.0" \
  uv run kiro2chat api > /tmp/kiro2chat.log 2>&1 &
```

## ğŸ“ Project Structure

```
kiro2chat/src/
â”œâ”€â”€ __init__.py              # Version
â”œâ”€â”€ app.py                   # FastAPI app, lifespan, CORS, exception handlers
â”œâ”€â”€ config.py                # Config (env > TOML > defaults)
â”œâ”€â”€ config_manager.py        # TOML config read/write + MCP config
â”œâ”€â”€ stats.py                 # Thread-safe request statistics
â”œâ”€â”€ webui.py                 # Gradio multi-page Web UI
â”œâ”€â”€ agent.py                 # Strands Agent + MCP tools
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py          # TokenManager (IdC token refresh)
â”‚   â”œâ”€â”€ client.py            # CodeWhisperer API client (httpx async)
â”‚   â”œâ”€â”€ converter.py         # OpenAI <-> CodeWhisperer protocol conversion
â”‚   â”œâ”€â”€ eventstream.py       # AWS EventStream binary parser
â”‚   â”œâ”€â”€ sanitizer.py         # Anti-prompt + response cleansing + identity scrub
â”‚   â”œâ”€â”€ health.py            # Health check utilities
â”‚   â””â”€â”€ token_counter.py     # CJK-aware token estimator
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ routes.py            # /v1/chat/completions, /v1/models (OpenAI)
â”‚   â”œâ”€â”€ anthropic_routes.py  # /v1/messages, /v1/messages/count_tokens (Anthropic)
â”‚   â””â”€â”€ agent_routes.py      # /v1/agent/* (Strands Agent)
â””â”€â”€ bot/
    â””â”€â”€ telegram.py          # Telegram Bot (aiogram)
```

## ğŸ“Š Tech Stack

| Component | Technology |
|-----------|-----------|
| Web Framework | FastAPI + Uvicorn |
| HTTP Client | httpx (async) |
| AI Agent | Strands Agents SDK |
| Web UI | Gradio 6 |
| Telegram Bot | aiogram 3 |
| Config | python-dotenv + TOML |
| Auth | kiro-cli SQLite â†’ AWS IdC OIDC |
| Package Manager | uv + hatchling |
| Python | â‰¥ 3.13 |

## ğŸ“ Changelog

### v1.0.0 â€” Production Release (2026-02-27)

#### ğŸ“¦ Production Ready
- **loguru** logging framework â€” structured, colorized, with stdlib interception
- **Prometheus /metrics** â€” requests, latency histogram, tokens, tool calls, errors, retries
- **Swagger /docs** â€” full OpenAPI documentation with endpoint descriptions
- **39 pytest tests** â€” sanitizer, token counter, converter, routes

#### ğŸ”§ Streaming Enhancements
- **Incremental tool_calls** â€” arguments sent in ~40 char chunks (OpenAI standard)
- **Anthropic thinking blocks** â€” passthrough support for extended thinking

#### ğŸ“ Documentation
- **docs/DEPLOYMENT.md** â€” complete deployment guide (systemd, nginx, monitoring)
- **CONTRIBUTING.md** â€” development setup and PR guidelines
- Bilingual README (EN/CN) with full changelog

### v0.9.0 â€” Retry Logic, Test Suite & Code Quality (2026-02-27)

#### ğŸ”„ Robustness
- **CW backend retry** â€” 5xx errors and timeouts retry with exponential backoff (1s â†’ 3s â†’ 10s, max 3 attempts)
- **2-hour client timeout** â€” `httpx` read timeout set to 7200s matching Nginx, no premature disconnects on long outputs
- **Request ID** â€” Every request gets an `x-request-id` header for tracing and debugging
- **API key security** â€” Moved from systemd unit file to `EnvironmentFile` with 600 permissions

#### ğŸ§ª Test Suite
- **39 pytest tests** across 4 modules:
  - `test_sanitizer` â€” identity scrub, tool filtering, streaming whitespace, anti-prompt
  - `test_token_counter` â€” tiktoken accuracy, CJK, message counting
  - `test_converter` â€” model override, anti-prompt injection, tool results, image extraction
  - `test_routes` â€” tool validation, filtering

#### ğŸ“¦ Code Quality
- **ruff** linting config (line-length=120, Python 3.13)
- **CONTRIBUTING.md** â€” development setup, testing, PR guidelines
- **pytest** config in `pyproject.toml`

### v0.8.0 â€” Accurate Token Counting & Nginx Optimization (2026-02-26)

#### ğŸ“Š Accurate Token Counting
- Replaced character-based heuristic with **tiktoken cl100k_base** encoding
- Chinese text accuracy improved from Â±48% error to **exact match**
- All token counts now match OpenAI's tokenizer precisely
- Graceful fallback to heuristic if tiktoken unavailable

#### ğŸ”§ Nginx Optimization
- `proxy_read_timeout` / `proxy_send_timeout`: 300s â†’ **7200s** (2 hours for long outputs)
- `proxy_http_version`: added **1.1** (required for SSE streaming)
- `proxy_connect_timeout`: added **60s**
- `chunked_transfer_encoding`: **on**, `proxy_cache`: **off**

### v0.7.0 â€” Image Support & Production Deployment (2026-02-26)

#### ğŸ–¼ï¸ Image Support
- OpenAI `image_url` (data URI base64) â†’ CW `images` format conversion
- Anthropic `image` blocks (base64 + URL) â†’ CW `images` format conversion
- Tested: pixel color recognition works end-to-end through public endpoint

#### ğŸ”§ Production Deployment
- **systemd service** â€” `Restart=always` with 3s delay, auto-start on boot
- Replaces nohup/supervisor.sh with proper process management
- `journalctl -u kiro2chat -f` for unified log viewing

### v0.6.0 â€” MCP Tool Calling & Streaming Fixes (2026-02-26)

**Major: Full MCP tool calling support through client SDKs**

#### MCP Tool Calling
- `toolUseEvent` streaming support â€” aggregates incremental chunks into complete tool_calls
- Tool result round-trip fixed â€” client MCP tools can search/scrape and return results correctly
- History building fix â€” assistant messages with toolUses correctly placed in CW history
- JSON content block parsing â€” nested content blocks flattened to plain text for CW backend
- Tool result truncation at 50K chars

#### Anti-Prompt Rebalancing
- Rewrote anti-prompt to encourage user-provided tool usage while blocking Kiro IDE tools
- Explicitly distinguishes: IDE tools (blocked) vs. user API tools (actively used)

#### Streaming Markdown Fix
- Fixed `sanitize_text()` stripping whitespace from streaming chunks
- Streaming chunks now preserve original whitespace for proper Markdown rendering

#### Token Usage Estimation
- Added `token_counter.py` with CJK-aware character-based estimation
- OpenAI: `prompt_tokens`, `completion_tokens`, `total_tokens`
- Anthropic: `input_tokens`, `output_tokens`

### v0.5.0 â€” API Gateway (2026-02-26)

- Full OpenAI + Anthropic dual protocol support
- Backend fixed to Claude Opus 4.6 1M
- Three-layer system prompt sanitization (28/28 tests pass)
- Parameter passthrough, tool_choice, tool validation
- CORS, global exception handlers, health check
- systemd service template

### v0.4.0 â€” Agent Integration
### v0.3.0 â€” Tool Calling
### v0.2.0 â€” Web UI
### v0.1.0 â€” Initial Release

## ğŸ‘¥ Contributors

<table>
  <tr>
    <td align="center">
      <a href="https://github.com/aleck">
        <img src="https://github.com/aleck.png?size=100" width="100" height="100" style="border-radius:50%" alt="Aleck"/><br/>
        <sub><b>Aleck</b></sub>
      </a><br/>
      <sub>Original Author</sub>
    </td>
    <td align="center">
      <a href="https://github.com/neosun100">
        <img src="https://github.com/neosun100.png?size=100" width="100" height="100" style="border-radius:50%" alt="Neo"/><br/>
        <sub><b>Neo</b></sub>
      </a><br/>
      <sub>API Gateway & Sanitization</sub>
    </td>
  </tr>
</table>

**[Aleck](https://github.com/aleck)** designed the core architecture â€” CodeWhisperer protocol reverse engineering, EventStream binary parser, and kiro-cli token management.

**[Neo](https://github.com/neosun100)** extended the project into a production-ready API Gateway:
- Full OpenAI + Anthropic dual-protocol compatibility
- Three-layer system prompt sanitization (28/28 adversarial tests pass)
- MCP tool calling with `toolUseEvent` streaming aggregation
- Image support (OpenAI `image_url` + Anthropic `image` blocks)
- Accurate token counting via tiktoken
- Nginx optimization for long-running SSE streams
- systemd production deployment
- Bilingual documentation (EN/CN)

We welcome contributions from the community! Whether it's bug fixes, new features, documentation improvements, or test cases â€” all contributions are appreciated.

## ğŸ“„ License

MIT
